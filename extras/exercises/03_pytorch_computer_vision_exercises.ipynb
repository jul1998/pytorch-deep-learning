{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "97f9fecb5a5b4c15a229e5c670914201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c61f18222c149768915c3117bdcc9b1",
              "IPY_MODEL_bdd3afb5f8e44088963ab2e2dbc95d46",
              "IPY_MODEL_ca8c34096e9640b38ab9297061531d2e"
            ],
            "layout": "IPY_MODEL_b01ae2cd049548d0b0cde3855f21c0ab"
          }
        },
        "0c61f18222c149768915c3117bdcc9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a723d7a2898455a8aaa73a0dbaa38a1",
            "placeholder": "​",
            "style": "IPY_MODEL_4fd9f736730743c08e64a54f0fe0d0b7",
            "value": "100%"
          }
        },
        "bdd3afb5f8e44088963ab2e2dbc95d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe789521c613429cb053dbcd6f1c4f17",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afc7ac41e75641b194570af69bb6892a",
            "value": 5
          }
        },
        "ca8c34096e9640b38ab9297061531d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c89fbaf7eb9c458c81424993f3f99074",
            "placeholder": "​",
            "style": "IPY_MODEL_f79ea03879114c9d8fe0fdb237ada07e",
            "value": " 5/5 [03:10&lt;00:00, 37.86s/it]"
          }
        },
        "b01ae2cd049548d0b0cde3855f21c0ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a723d7a2898455a8aaa73a0dbaa38a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fd9f736730743c08e64a54f0fe0d0b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe789521c613429cb053dbcd6f1c4f17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc7ac41e75641b194570af69bb6892a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c89fbaf7eb9c458c81424993f3f99074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f79ea03879114c9d8fe0fdb237ada07e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jul1998/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import datasets\n",
        "\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "GaeYzOTLwWh2"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the MNIST train dataset\n",
        "train_data = datasets.MNIST(root=\".\",\n",
        "                            train=True,\n",
        "                            download=True,\n",
        "                            transform=transforms.ToTensor()) # do we want to transform the data as we download it?\n",
        "\n",
        "# Get the MNIST test dataset\n",
        "test_data = datasets.MNIST(root=\".\",\n",
        "                           train=False,\n",
        "                           download=True,\n",
        "                           transform=transforms.ToTensor())\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "d02767e6-0f7e-4a73-cb8f-fe6c4456a80a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 80679092.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 45098918.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 23893628.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7084614.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Camera and photo apps use computer vision to enhance and sort images.\n",
        "\n",
        "Modern cars use computer vision to avoid other cars and stay within lane lines.\n",
        "\n",
        "Manufacturers use computer vision to identify defects in various products.\n",
        "\n",
        "Security cameras use computer vision to detect potential intruders."
      ],
      "metadata": {
        "id": "YG6pI9ZAfDgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is an undesirable machine learning behavior that occurs when the machine learning model gives accurate predictions for training data but not for new data."
      ],
      "metadata": {
        "id": "0ZStx7RYfJDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parada antecipada\n",
        "A parada antecipada pausa a fase de treinamento antes que o modelo de machine learning aprenda o ruído nos dados. No entanto, acertar o tempo é importante. Caso contrário, o modelo ainda não fornecerá resultados precisos.\n",
        "\n",
        "Poda\n",
        "Você pode identificar vários recursos ou parâmetros que afetam a previsão final ao construir um modelo. A seleção de recursos, ou poda, identifica os recursos mais importantes dentro do conjunto de treinamento e elimina os irrelevantes. Por exemplo, para prever se uma imagem é animal ou humana, você pode observar vários parâmetros de entrada, como formato do rosto, posição da orelha, estrutura corporal etc. Você pode priorizar o formato do rosto e ignorar o formato dos olhos.\n",
        "\n",
        "Regularização\n",
        "A regularização é uma coleção de técnicas de treinamento/otimização que buscam reduzir sobreajuste. Esses métodos tentam eliminar os fatores que não afetam os resultados da previsão classificando os recursos com base na importância. Por exemplo, cálculos matemáticos aplicam um valor de penalidade a feições com impacto mínimo. Considere um modelo estatístico tentando prever os preços da habitação de uma cidade em 20 anos. A regularização daria um valor de penalidade mais baixo a características como crescimento populacional e renda média anual, mas um valor de penalidade mais alto para a temperatura média anual da cidade.\n",
        "\n",
        "Agrupamento em conjuntos\n",
        "O agrupamento em conjuntos combina previsões de vários algoritmos de machine learning separados. Alguns modelos são chamados de alunos fracos porque seus resultados geralmente são imprecisos. Os métodos de agrupamento em conjuntos combinam todos os alunos fracos para obter resultados mais precisos. Eles usam vários modelos para analisar dados de amostra e escolher os resultados mais precisos. Os dois principais métodos de conjunto são o empacotamento e o impulsionamento. O impulsionamento treina diferentes modelos de machine learning, um após o outro, para obter o resultado final, enquanto o empacotamento os treina em paralelo.\n",
        "\n",
        "Aumento de dados\n",
        "O aumento de dados é uma técnica de machine learning que altera ligeiramente os dados de amostra toda vez que o modelo os processa. Você pode fazer isso alterando os dados de entrada de maneiras pequenas. Quando feito com moderação, o aumento de dados faz com que os conjuntos de treinamento pareçam exclusivos do modelo e impede que o modelo aprenda suas características. Por exemplo, aplicar transformações como translação, inversão e rotação às imagens de entrada."
      ],
      "metadata": {
        "id": "KFErbaUnfQWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqZaJIRMbFtS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# IMport torch vision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")\n",
        "\n",
        "\n",
        "# set up training data\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        ")"
      ],
      "metadata": {
        "id": "SHjeuN81bHza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd0485bc-9a24-4714-c1b7-40bef532b56e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.0.1+cu118\n",
            "torchvision version: 0.15.2+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See firt training sample\n",
        "# Data is in tuple form (image, label)\n",
        "img = train_data[0][0]\n",
        "label = train_data[0][1]\n",
        "print(f\"Image:\\n {img}\")\n",
        "print(f\"Label:\\n {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1au9ondxtrNw",
        "outputId": "f61f7e09-840f-434d-a0e5-93ea4fa3631f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image:\n",
            " tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
            "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
            "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
            "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
            "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
            "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
            "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
            "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
            "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
            "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
            "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
            "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
            "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
            "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
            "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
            "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
            "Label:\n",
            " 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Isto está formatado como código\n",
        "```\n",
        "\n",
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kho2OzWNt3yF"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iItuRx1Zt35s",
        "outputId": "6f4af0af-4e0e-4290-cb5d-b27ccd827448"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 60000, 10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  See clases\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12bb85a2-e070-4f94-802f-a81df43df341"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 - zero',\n",
              " '1 - one',\n",
              " '2 - two',\n",
              " '3 - three',\n",
              " '4 - four',\n",
              " '5 - five',\n",
              " '6 - six',\n",
              " '7 - seven',\n",
              " '8 - eight',\n",
              " '9 - nine']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for i in range(5):\n",
        "  img = train_data[i][0]\n",
        "  print(img.shape)\n",
        "  img_squeeze = img.squeeze()\n",
        "  print(img_squeeze.shape)\n",
        "  label = train_data[i][1]\n",
        "  plt.figure(figsize=(3, 3))\n",
        "  plt.imshow(img_squeeze, cmap=\"gray\")\n",
        "  plt.title(label)\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ohTx7OJOuEQl",
        "outputId": "955cbd23-d9b2-4f7f-dcf4-590e5fd600cc"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAERCAYAAABSGLrIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAGKUlEQVR4nO3dK28UbRjH4WcaEkgQ5SQWDPsJoAZXgWhISRAoLHyBOpIaEgKKBEU42DZ4BEETwGwQeIqBNOGQEkRFFWLnla8hzywMu1v6vy57Dzu3+fGEzDLbtG3bFuBAW5j3AsD0CR0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCD3E3t5euX37dlldXS0nTpwoTdOUzc3Nea/FjAg9xI8fP8rdu3fL+/fvy/nz5+e9DjN2aN4LMBunT58u3759K4PBoLx7965cuHBh3isxQ070EIcPHy6DwWDeazAnQocAQocAQocAQocAQocAQocAQocAvjAT5NGjR2V3d7d8/fq1lFLKixcvyufPn0sppaytrZXFxcV5rscUNV73nGM4HJbt7e1fzj59+lSGw+FsF2JmhA4B/BsdAggdAggdAggdAggdAggdAggdAkz8zbimaaa5B/CHJvkqjBMdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAhya9wJkunXrVuc1d+7cqc4XFurn1MWLF6vzN2/edO5wUDjRIYDQIYDQIYDQIYDQIYDQIYDQIYDn6EzFjRs3qvP19fXOzxiPx712aNu2158/SJzoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEMAXZpiKs2fPVudHjhyZ0SaU4kSHCEKHAEKHAEKHAEKHAEKHAEKHAJ6j80dWVlaq87W1td732Nraqs6vXLlSne/s7PTe4aBwokMAoUMAoUMAoUMAoUMAoUMAoUMAz9H5peXl5ep8Y2OjOl9cXOy9w/3796vz7e3t3vdI4USHAEKHAEKHAEKHAEKHAEKHAEKHAJ6j80vXr1+vzs+cOdPr81+/ft15zdOnT3vdg/850SGA0CGA0CGA0CGA0CGA0CGA0CGA0CFA07ZtO9GFTTPtXZiRU6dOdV7T9eMH4/G4Ot/d3a3Or1271rnDq1evOq+hlEkSdqJDAKFDAKFDAKFDAKFDAKFDAKFDAC+eOICGw2F1/uzZs6nv8PDhw+rcM/LZcqJDAKFDAKFDAKFDAKFDAKFDAKFDAM/RD6DV1dXq/Ny5c73v8fLly+r8wYMHve/B3+NEhwBChwBChwBChwBChwBChwBChwDe6/4Punr1anW+ublZnR89erTzHqPRqDrvei9713vh+Xu81x0opQgdIggdAggdAggdAggdAggdAggdAnjxxD60H36A4ePHj9W5L8T8W5zoEEDoEEDoEEDoEEDoEEDoEEDoEMBz9H1ofX29Oh+Px1Pf4d69e1O/B7PjRIcAQocAQocAQocAQocAQocAQocAnqPP2NLSUuc1ly5dmuoOz58/77zmw4cPU92B2XKiQwChQwChQwChQwChQwChQwChQ4CmneRX1EspTdNMe5cI379/77zm+PHjve7x9u3b6vzy5cudn7G3t9drB2ZnkoSd6BBA6BBA6BBA6BBA6BBA6BBA6BBA6BDAiydm7OTJk53X9P2BhidPnlTnvgyTx4kOAYQOAYQOAYQOAYQOAYQOAYQOATxH/8s2Njaq84WF6f/dOhqNpn4P/i1OdAggdAggdAggdAggdAggdAggdAjgOfpvWlpaqs5XVlaq80n+r/nPnz+r88ePH1fnOzs7nfcgixMdAggdAggdAggdAggdAggdAggdAniO/puOHTtWnQ8Gg973+PLlS3V+8+bN3vcgixMdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAnjxxG/a2tqqzkejUXW+vLz8N9eBiTjRIYDQIYDQIYDQIYDQIYDQIYDQIUDTtm070YVNM+1dgD8wScJOdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAhwaNILJ/ydB2AfcqJDAKFDAKFDAKFDAKFDAKFDAKFDAKFDAKFDgP8AzUbb2RRpmrMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69sPz-zmuESY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n",
        "\n",
        "# Create train dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=32,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=32,\n",
        "                             shuffle=False)\n",
        ""
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR9GV2d211oX",
        "outputId": "6f83e773-9c68-421c-af9b-13548d0911c9"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7f080e3176d0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7f080e316c20>)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for sample in next(iter(train_dataloader)):\n",
        "  print(sample.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P4gc4F711qo",
        "outputId": "fae2a3ad-6702-47ad-b57f-9c2ddfe88bc5"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch import nn\n",
        "class MNIST_model(torch.nn.Module):\n",
        "  \"\"\"Model capable of predicting on MNIST dataset.\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=input_shape,\n",
        "                out_channels=hidden_units,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(in_channels=hidden_units,\n",
        "                out_channels=hidden_units,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=hidden_units,\n",
        "                out_channels=hidden_units,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(in_channels=hidden_units,\n",
        "                out_channels=hidden_units,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(in_features=hidden_units*7*7,\n",
        "                out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    # print(f\"Output shape of conv block 1: {x.shape}\")\n",
        "    x = self.conv_block_2(x)\n",
        "    # print(f\"Output shape of conv block 2: {x.shape}\")\n",
        "    x = self.classifier(x)\n",
        "    # print(f\"Output shape of classifier: {x.shape}\")\n",
        "    return x"
      ],
      "metadata": {
        "id": "5IKNF22XbKYS"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device\n",
        "model = MNIST_model(input_shape=1,\n",
        "                    hidden_units=10,\n",
        "                    output_shape=10).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKGh1Zq3fzbX",
        "outputId": "5b000992-ce0e-45d0-8c0d-ea1ff2b5a0bb"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNIST_model(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%time\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Train on CPU\n",
        "model_cpu = MNIST_model(input_shape=1,\n",
        "                        hidden_units=10,\n",
        "                        output_shape=10).to(\"cpu\")\n",
        "\n",
        "# Create a loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_cpu.parameters(), lr=0.1)\n",
        "\n",
        "### Training loop\n",
        "epochs = 5\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  train_loss = 0\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    model_cpu.train()\n",
        "\n",
        "    # Put data on CPU\n",
        "    X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
        "\n",
        "    # Forward pass\n",
        "    y_pred = model_cpu(X)\n",
        "\n",
        "    # Loss calculation\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "\n",
        "    # Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # Step the optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "  # Adjust train loss for number of batches\n",
        "  train_loss /= len(train_dataloader)\n",
        "\n",
        "  ### Testing loop\n",
        "  test_loss_total = 0\n",
        "\n",
        "  # Put model in eval mode\n",
        "  model_cpu.eval()\n",
        "\n",
        "  # Turn on inference mode\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X_test, y_test) in enumerate(test_dataloader):\n",
        "      # Make sure test data on CPU\n",
        "      X_test, y_test = X_test.to(\"cpu\"), y_test.to(\"cpu\")\n",
        "      test_pred = model_cpu(X_test)\n",
        "      test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "      test_loss_total += test_loss\n",
        "\n",
        "    test_loss_total /= len(test_dataloader)\n",
        "\n",
        "  # Print out what's happening\n",
        "  print(f\"Epoch: {epoch} | Loss: {train_loss:.3f} | Test loss: {test_loss_total:.3f}\")"
      ],
      "metadata": {
        "id": "jSo6vVWFbNLD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "97f9fecb5a5b4c15a229e5c670914201",
            "0c61f18222c149768915c3117bdcc9b1",
            "bdd3afb5f8e44088963ab2e2dbc95d46",
            "ca8c34096e9640b38ab9297061531d2e",
            "b01ae2cd049548d0b0cde3855f21c0ab",
            "9a723d7a2898455a8aaa73a0dbaa38a1",
            "4fd9f736730743c08e64a54f0fe0d0b7",
            "fe789521c613429cb053dbcd6f1c4f17",
            "afc7ac41e75641b194570af69bb6892a",
            "c89fbaf7eb9c458c81424993f3f99074",
            "f79ea03879114c9d8fe0fdb237ada07e"
          ]
        },
        "outputId": "51eb52c4-4fb2-421f-bfc2-565706a2ffcf"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97f9fecb5a5b4c15a229e5c670914201"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.387 | Test loss: 0.084\n",
            "Epoch: 1 | Loss: 0.079 | Test loss: 0.051\n",
            "Epoch: 2 | Loss: 0.061 | Test loss: 0.057\n",
            "Epoch: 3 | Loss: 0.051 | Test loss: 0.036\n",
            "Epoch: 4 | Loss: 0.045 | Test loss: 0.042\n",
            "CPU times: user 3min 8s, sys: 288 ms, total: 3min 8s\n",
            "Wall time: 3min 10s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUR3jk63iHha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z4v86Uh1iHj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NBRfYT1viHmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "61lTCrEAiHqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}